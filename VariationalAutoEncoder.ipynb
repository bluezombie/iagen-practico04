{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Práctico VAE (Variational AutoEncoders)\n",
        "\n",
        "El objetivo de este práctico es explorar las Variational Autoencoders tanto en su implementación como sus bases teóricas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnNK0YkJvNYV"
      },
      "outputs": [],
      "source": [
        "#!python -m pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voaWjz0Z0VoP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchinfo\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from torchvision.utils import save_image, make_grid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svlrOe-jl_Ue"
      },
      "outputs": [],
      "source": [
        "# create a transofrm to apply to each datapoint\n",
        "transform = transforms.ToTensor() #transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# download the MNIST datasets\n",
        "path = '~/datasets'\n",
        "train_dataset = MNIST(path, transform=transform, download=True)\n",
        "test_dataset  = MNIST(path, transform=transform, download=True)\n",
        "\n",
        "# create train and test dataloaders\n",
        "batch_size = 100\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(f\"Running on {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W4t-pYxxSS5"
      },
      "outputs": [],
      "source": [
        "# get a batch of images\n",
        "dataiter = iter(train_loader)\n",
        "batch_images = next(dataiter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypoJFTARxbbN",
        "outputId": "2d993388-8c99-4c64-bcb8-c990eb3ea70d"
      },
      "outputs": [],
      "source": [
        "batch_images[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DssjxI36xstW",
        "outputId": "3bf1bbc8-aa5e-4c19-a833-15537c7fb6bd"
      },
      "outputs": [],
      "source": [
        "# flatten batch\n",
        "flatten_batch = batch_images[0].view(batch_size, 1*28*28).to(DEVICE)\n",
        "flatten_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "Uv247-ZrCURC",
        "outputId": "db924035-4865-4c3e-e6ab-6591229711e8"
      },
      "outputs": [],
      "source": [
        "# get 25 sample training images for visualization\n",
        "num_samples = 25\n",
        "sample_images = [batch_images[0][i,0] for i in range(num_samples)]\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.1)\n",
        "\n",
        "for ax, im in zip(grid, sample_images):\n",
        "    ax.imshow(im, cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=400, z_dim=200, latent_dim=2, device='cpu'):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # TODO: Completar esta sección. Definir las capas de la VAE.\n",
        "        # encoder\n",
        "        self.encoder = ...\n",
        "\n",
        "        # latent mean and variance\n",
        "        self.mean_layer = ...\n",
        "        self.logvar_layer = ...\n",
        "\n",
        "        # decoder\n",
        "        self.decoder = ...\n",
        "\n",
        "    def encode(self, x):\n",
        "        # TODO: Completar esta sección. Debes codificar 'x' usando la capa encoder\n",
        "        # computar la media y la varianza de la distribución latente.\n",
        "        # Devuelve la media y varianza\n",
        "        ...\n",
        "\n",
        "    def reparameterization(self, mean, var):\n",
        "        # TODO: Completar esta sección. Aplica el truco de reparametrización.\n",
        "        # Devuelve 'z' luego de hacer el reparametrization trick.\n",
        "        ...\n",
        "\n",
        "    def decode(self, z):\n",
        "        # TODO: Completar esta sección. Usar el decodificador para transformar 'z' \n",
        "        #      de nuevo a una representación del espacio original.\n",
        "        # Devuelve la reconstrucción.\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Completar esta sección. Sigue el flujo de la VAE:\n",
        "        # 1. Codificar\n",
        "        # 2. Reparametrizar\n",
        "        # 3. Decodificar\n",
        "        # Devuelve la reconstrucción, la media y la varianza.\n",
        "        ...\n",
        "    \n",
        "    def generate(self, num_samples=1):\n",
        "        # TODO: Completar esta sección. Generar nuevas muestras a partir de la distribución latente.\n",
        "        # Devuelve las nuevas muestras generadas.\n",
        "        ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOuxwnnVnbBJ"
      },
      "outputs": [],
      "source": [
        "LR = ...\n",
        "\n",
        "model = VAE(device=DEVICE).to(DEVICE)\n",
        "optimizer = Adam(model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW5aiqWCvcGy",
        "outputId": "5cb8514b-8927-40ba-c16b-06414197a28d"
      },
      "outputs": [],
      "source": [
        "torchinfo.summary(model, input_size=(100,784), col_names = ('input_size', 'output_size', 'num_params'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Función de Pérdida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlwQdnotney0"
      },
      "outputs": [],
      "source": [
        "def loss_function(x, x_hat, mean, log_var):\n",
        "    # TODO: Completar esta sección. Implementar la función de pérdida de la VAE.\n",
        "    # 1) Calcule la pérdida de reconstrucción (reconstruction loss) entre x y x_hat.\n",
        "    reproduction_loss = ...\n",
        "    # 2) Calcule la divergencia KL (Kullback-Leibler divergence) entre la distribución latente y una distribución normal estándar.\n",
        "    KLD = - 0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
        "    # 3) Devuelva la pérdida.\n",
        "    return ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwWtxYrUF826"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, epochs, device, x_dim=784):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        overall_loss = 0\n",
        "        for batch_idx, (x, _) in enumerate(train_loader):\n",
        "            x = x.view(batch_size, x_dim).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x_hat, mean, log_var = model(x)\n",
        "            loss = loss_function(x, x_hat, mean, log_var)\n",
        "\n",
        "            overall_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss/(batch_idx*batch_size))\n",
        "    return overall_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP-7CIF3GYUA",
        "outputId": "eb61e7bc-2926-4d53-9ad4-a3146ea0ee35"
      },
      "outputs": [],
      "source": [
        "train(model.to(DEVICE), optimizer, epochs=10, device=DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwy7y4Dxa945"
      },
      "outputs": [],
      "source": [
        "def generate_digit(z_dim=2):\n",
        "    x_decoded = model.generate()\n",
        "    digit = x_decoded.detach().cpu().reshape(28, 28)\n",
        "    #plt.title(f'[{z_sample[0,0]},{z_sample[0,1]}]')\n",
        "    plt.imshow(digit, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "d3xBvZlibWwG",
        "outputId": "24ac80d7-da41-405d-d5df-d90f6d44facc"
      },
      "outputs": [],
      "source": [
        "generate_digit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mostrar el espacio latente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgFh4FOvKVmb"
      },
      "outputs": [],
      "source": [
        "def plot_latent_space(model, scale=5.0, n=25, digit_size=28, figsize=15):\n",
        "    # display a n*n 2D manifold of digits\n",
        "    figure = np.zeros((digit_size * n, digit_size * n))\n",
        "\n",
        "    # construct a grid\n",
        "    grid_x = np.linspace(-scale, scale, n)\n",
        "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
        "\n",
        "    for i, yi in enumerate(grid_y):\n",
        "        for j, xi in enumerate(grid_x):\n",
        "            z_sample = torch.tensor([[xi, yi]], dtype=torch.float).to(DEVICE)\n",
        "            x_decoded = model.decode(z_sample)\n",
        "            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n",
        "            figure[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size,] = digit\n",
        "\n",
        "    plt.figure(figsize=(figsize, figsize))\n",
        "    plt.title('VAE Latent Space Visualization')\n",
        "    start_range = digit_size // 2\n",
        "    end_range = n * digit_size + start_range\n",
        "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
        "    sample_range_x = np.round(grid_x, 1)\n",
        "    sample_range_y = np.round(grid_y, 1)\n",
        "    plt.xticks(pixel_range, sample_range_x)\n",
        "    plt.yticks(pixel_range, sample_range_y)\n",
        "    plt.xlabel(\"z[0]\")\n",
        "    plt.ylabel(\"z[1]\")\n",
        "    plt.imshow(figure, cmap=\"Greys_r\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iaZxxvMQgxaO",
        "outputId": "ffedc2d3-2609-4d74-ff06-ebbc515395a4"
      },
      "outputs": [],
      "source": [
        "plot_latent_space(model, scale=1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejercicios\n",
        "\n",
        "1. Complete el código.\n",
        "2. ¿Por qué es necesario el truco de reparametrización en las VAE?\n",
        "3. ¿Qué representan las variables mean y var en la VAE?\n",
        "4. Cree y entrene nuevas VAE modificando los hiperparámetros.\n",
        "5. ¿Cómo afecta la elección del tamaño del espacio latente al rendimiento de la VAE?\n",
        "6. ¿Qué rol juega el término de regularización KL-divergence en la función de pérdida de la VAE?\n",
        "7. Explique que ve en la imágen que se genera cuando llamamos a la función `plot_latent_space`. Si cambiamos la dimensión del espacio latente, ¿qué pasaría con esta gráfica?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "IAGen",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
